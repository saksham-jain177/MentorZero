{
  "project_overview": {
    "name": "MentorZero",
    "version": "0.1.0",
    "description": "An offline-first, zero-cost adaptive tutoring agent that runs locally with Ollama, performs Agentic RAG for cited answers, and includes AutoLearn (self-improvement) with LLM-as-a-judge",
    "type": "AI Tutoring Agent",
    "architecture": "Local-first, Agentic RAG + AZL (Autonomous Zero-label Learning)",
    "license": "MIT"
  },
  
  "core_components": {
    "backend": {
      "framework": "FastAPI",
      "language": "Python 3.10+",
      "llm_engine": "Ollama (local)",
      "database": "SQLite",
      "vector_store": "FAISS",
      "embeddings": "SentenceTransformers (all-MiniLM-L6-v2)",
      "api_endpoints": 15,
      "main_modules": [
        "api/routes.py - Main API endpoints",
        "agent/services/teaching.py - Core teaching logic",
        "agent/services/rag.py - Agentic RAG implementation",
        "agent/azl/generator.py - AZL example generation",
        "agent/azl/scorer.py - AZL scoring and validation",
        "agent/llm/ollama_client.py - LLM communication"
      ]
    },
    "frontend": {
      "technology": "Vanilla HTML/CSS/JavaScript",
      "ui_theme": "Futuristic neon/glass design",
      "pages": ["Chat", "Upload", "About", "AutoLearn"],
      "features": [
        "Real-time SSE streaming",
        "Keyboard shortcuts (Alt+T, Alt+L, /)",
        "Theme switching",
        "Chat persistence",
        "Health indicators",
        "Interactive AutoLearn observer"
      ]
    }
  },

  "key_features": {
    "agentic_rag": {
      "description": "Retrieval-Augmented Generation with autonomous agents",
      "capabilities": [
        "Document ingestion and chunking",
        "Semantic search with FAISS",
        "Query rewriting with LLM",
        "MMR (Maximal Marginal Relevance) diversification",
        "Hybrid ranking (Dense + BM25)",
        "Citation formatting for answers"
      ],
      "implementation": "agent/services/rag.py",
      "status": "Fully implemented"
    },
    
    "azl_autolearn": {
      "description": "Autonomous Zero-label Learning for self-improvement",
      "process": [
        "1. Generate synthetic Q/A pairs using LLM",
        "2. Self-evaluate using multiple validators",
        "3. LLM-as-a-judge scoring (correctness, clarity, usefulness)",
        "4. Auto-accept high-quality examples",
        "5. Regenerate failed examples with retry logic"
      ],
      "validators": [
        "length - Check answer length appropriateness",
        "duplicate - Detect duplicate content",
        "consistency - Verify Q/A alignment",
        "roundtrip - Test answer regeneration",
        "toxicity - Filter harmful content",
        "placeholder - Detect generic responses"
      ],
      "scoring_weights": {
        "length": 0.1,
        "duplicate": 0.1,
        "consistency": 0.2,
        "roundtrip": 0.2,
        "toxicity": 0.2,
        "placeholder": 0.2,
        "judge": 0.2
      },
      "implementation": "agent/azl/",
      "status": "Implemented with performance issues"
    },
    
    "teaching_service": {
      "description": "Adaptive teaching with multiple strategies",
      "strategies": [
        "neural_compression - 5 memory hooks",
        "socratic_dialogue - Question-based learning",
        "concrete_examples - Real-world examples",
        "visual_mapping - Mental imagery and diagrams",
        "spaced_repetition - Timed review intervals"
      ],
      "difficulty_levels": ["beginner", "intermediate", "advanced", "expert"],
      "features": [
        "Loop-Until-Mastered tracking",
        "Strategy performance monitoring",
        "Session management",
        "Context-aware explanations"
      ],
      "implementation": "agent/services/teaching.py",
      "status": "Fully implemented"
    },
    
    "voice_capabilities": {
      "stt": "Whisper (optional)",
      "tts": "ChatterboxTTS (optional)",
      "status": "Optional feature, not required"
    }
  },

  "current_limitations": {
    "performance_issues": {
      "azl_judge_latency": {
        "problem": "Reasoning models (gpt-oss:20b) take 10-30 seconds per evaluation",
        "impact": "Poor UX, frequent timeouts",
        "current_workaround": "Fast model fallback, but still slow"
      },
      "regeneration_failures": {
        "problem": "High failure rate in example regeneration",
        "symptoms": ["JSON parsing errors", "LLM output inconsistencies", "Timeout errors"],
        "root_cause": "LLM output variability and parsing robustness"
      }
    },
    
    "technical_debt": {
      "caching": {
        "current": "No Redis, only in-memory caches",
        "limitation": "Cache lost on restart, no persistence",
        "impact": "Redundant LLM calls, slower performance"
      },
      "error_handling": {
        "current": "Basic try-catch blocks",
        "limitation": "Insufficient error recovery and user feedback",
        "impact": "Silent failures, poor debugging"
      },
      "monitoring": {
        "current": "Basic health checks",
        "limitation": "No performance metrics, no evaluation logging",
        "impact": "Cannot track model improvement over time"
      }
    },
    
    "ui_ux_issues": {
      "observer_panel": {
        "problem": "Fixed height causes scrolling issues",
        "status": "Partially addressed"
      },
      "progress_indicators": {
        "problem": "Tiny visual indicators, hard to notice",
        "status": "Needs improvement"
      },
      "error_feedback": {
        "problem": "Generic error messages, no actionable feedback",
        "status": "Needs improvement"
      }
    }
  },

  "strengths": {
    "architecture": [
      "Offline-first design - No external dependencies",
      "Modular design - Easy to extend and modify",
      "Agentic RAG - Sophisticated retrieval system",
      "Local execution - Privacy and cost benefits"
    ],
    "azl_implementation": [
      "Comprehensive validation pipeline",
      "Multiple scoring dimensions",
      "Real-time streaming observer",
      "Robust parsing with fallbacks"
    ],
    "ui_design": [
      "Futuristic, modern interface",
      "Responsive design",
      "Keyboard shortcuts for power users",
      "Real-time updates via SSE"
    ],
    "extensibility": [
      "Plugin architecture for teaching strategies",
      "Configurable scoring weights",
      "Multiple LLM model support",
      "Optional voice capabilities"
    ]
  },

  "planned_improvements": {
    "performance_optimization": {
      "smart_caching": {
        "description": "Implement hybrid caching strategy",
        "approach": "SQLite + in-memory cache with TTL",
        "benefit": "90% faster average response time"
      },
      "judge_cascade": {
        "description": "Fast model first, reasoning model only when needed",
        "approach": "Pre-filtering with confidence thresholds",
        "benefit": "80% of evaluations in 1-2 seconds"
      },
      "background_processing": {
        "description": "Move heavy evaluations to background",
        "approach": "Async processing with progress updates",
        "benefit": "Non-blocking UI, better UX"
      }
    },
    
    "evaluation_framework": {
      "phase_1": {
        "title": "Enhanced Process Evaluation",
        "features": [
          "Reasoning chain analysis",
          "Step-by-step quality metrics",
          "Decision tree evaluation"
        ]
      },
      "phase_2": {
        "title": "Multi-Modal Assessment",
        "features": [
          "Human feedback collection",
          "A/B testing framework",
          "User satisfaction metrics"
        ]
      },
      "phase_3": {
        "title": "Advanced Optimization",
        "features": [
          "Adversarial testing",
          "Continuous learning metrics",
          "Performance prediction models"
        ]
      },
      "phase_4": {
        "title": "Production Monitoring",
        "features": [
          "Real-time performance dashboards",
          "Automated alerting systems",
          "Continuous improvement loops"
        ]
      }
    },
    
    "ui_enhancements": {
      "observer_panel": {
        "description": "Fixed-height scrollable modal",
        "features": ["Better progress visualization", "Copy/download logs", "Real-time metrics"]
      },
      "error_handling": {
        "description": "Comprehensive error feedback system",
        "features": ["Detailed error messages", "Recovery suggestions", "Debug information"]
      },
      "accessibility": {
        "description": "Improve usability for non-tech users",
        "features": ["Better navigation", "Clearer labels", "Help tooltips"]
      }
    }
  },

  "technical_specifications": {
    "dependencies": {
      "core": [
        "fastapi>=0.104.0",
        "uvicorn>=0.24.0",
        "pydantic>=2.0.0",
        "sqlalchemy>=2.0.0",
        "faiss-cpu>=1.7.4",
        "sentence-transformers>=2.2.0"
      ],
      "optional": [
        "openai-whisper (STT)",
        "chatterbox-tts (TTS)",
        "requests (HTTP client)"
      ]
    },
    
    "environment_variables": {
      "required": [
        "MZ_OLLAMA_MODEL - Main LLM model",
        "MZ_OLLAMA_HOST - Ollama server URL"
      ],
      "optional": [
        "MZ_JUDGE_MODEL - Judge model (defaults to main model)",
        "MZ_JUDGE_MODEL_HEAVY - Heavy reasoning model",
        "MZ_JUDGE_MARGIN - Cascade threshold margin",
        "MZ_AZL_PASS_THRESHOLD - AZL acceptance threshold",
        "MZ_AZL_MAX_ATTEMPTS - Max regeneration attempts",
        "MZ_AZL_DAILY_BUDGET - Daily generation limit"
      ]
    },
    
    "data_storage": {
      "database": "SQLite (mentorzero.db)",
      "vector_index": "FAISS (faiss.index)",
      "metadata": "JSON (faiss_meta.json)",
      "cache": "In-memory (no persistence)"
    }
  },

  "api_endpoints": {
    "teaching": [
      "POST /teach - Start teaching session",
      "POST /submit_answer - Submit answer and get feedback",
      "POST /optimize - Optimize teaching content",
      "POST /reask - Regenerate content with variants"
    ],
    "rag": [
      "POST /upload - Upload and index text",
      "POST /scrape_fetch - Scrape and index URL",
      "GET /retrieve - Retrieve relevant chunks"
    ],
    "azl": [
      "GET /azl/autolearn_stream - Stream AutoLearn progress",
      "POST /azl/propose - Generate AZL examples",
      "POST /azl/validate - Validate examples"
    ],
    "system": [
      "GET /llm_health - Check LLM health",
      "GET /judge_health - Check judge health",
      "GET /metrics/timings - Performance metrics"
    ]
  },

  "development_status": {
    "current_phase": "MVP with performance optimization needed",
    "completion_percentage": 75,
    "working_features": [
      "Agentic RAG - Fully functional",
      "Teaching Service - Fully functional", 
      "Basic AZL - Functional but slow",
      "UI/UX - Mostly complete",
      "API - Complete"
    ],
    "blocking_issues": [
      "AZL performance (reasoning model latency)",
      "Regeneration failure rate",
      "Missing evaluation framework"
    ],
    "next_milestones": [
      "Implement smart caching",
      "Optimize judge cascade",
      "Add evaluation framework",
      "Improve error handling"
    ]
  },

  "what_is_azl": {
    "definition": "Autonomous Zero-label Learning - A self-improvement system where the agent generates, evaluates, and accepts its own training data without external human validation",
    "process": [
      "1. Generate synthetic Q/A pairs about a topic",
      "2. Self-evaluate using multiple validation criteria",
      "3. Use LLM-as-a-judge for quality assessment",
      "4. Auto-accept high-quality examples",
      "5. Regenerate and retry failed examples",
      "6. Build a self-curated training dataset"
    ],
    "benefits": [
      "No human annotation required",
      "Continuous self-improvement",
      "Domain-specific knowledge building",
      "Scalable training data generation"
    ],
    "challenges": [
      "Quality control without human oversight",
      "Computational cost of evaluation",
      "Risk of reinforcing model biases",
      "Need for robust validation pipelines"
    ]
  },

  "what_is_agentic_rag": {
    "definition": "Retrieval-Augmented Generation enhanced with autonomous agents that can dynamically decide retrieval strategies, rewrite queries, and adapt to user needs",
    "components": [
      "Document ingestion and chunking",
      "Semantic embedding and indexing",
      "Query understanding and rewriting",
      "Intelligent retrieval with MMR",
      "Hybrid ranking (semantic + keyword)",
      "Context-aware answer generation"
    ],
    "advantages": [
      "More accurate than traditional RAG",
      "Adaptive to different query types",
      "Better context utilization",
      "Reduced hallucination"
    ],
    "vs_traditional_rag": [
      "Traditional RAG: Static retrieval → Generation",
      "Agentic RAG: Query analysis → Strategy selection → Retrieval → Regeneration → Answer"
    ]
  },

  "deployment": {
    "local_development": {
      "requirements": ["Python 3.10+", "Ollama running on localhost:11434"],
      "setup": ["pip install -r requirements.txt", "ollama pull llama3.1:8b-instruct-q4_K_M", "uvicorn api.main:app --reload"],
      "access": "http://localhost:8000"
    },
    "production": {
      "recommendations": ["Docker containerization", "Redis for caching", "PostgreSQL for database", "Load balancing for multiple instances"],
      "scaling": "Horizontal scaling with shared vector store"
    }
  }
}